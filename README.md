This repository contains a Jupyter notebook (Pyspark_Practice.ipynb) focused on fundamental operations in Apache Spark using PySpark.

The notebook is structured to cover hands-on practice for both RDDs (Resilient Distributed Datasets) and DataFrames, demonstrating essential data analysis and manipulation techniques.

Key Areas Covered
RDD Practice
Basic Statistics: Calculating sum, average, min, max, and count on a range of numbers.

Filtering & Grouping: Counting even vs. odd numbers and grouping custom data by age.

Text Analysis: Loading a text file, counting lines, and performing basic word frequency analysis (tokenization, stop-word removal).

DataFrame Practice
Data Manipulation: Loading data, viewing schema, selecting columns, and filtering rows.

Aggregation: Computing overall average salary and grouped aggregations (average salary by name).

Data Cleaning: Handling missing values by filling nulls with default strings or column means.
