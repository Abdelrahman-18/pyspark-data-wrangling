🐍 PySpark Fundamentals Practice
A concise Jupyter notebook (Pyspark_Practice.ipynb) for mastering core Apache Spark data processing using the PySpark API.

This repository is an excellent resource for anyone looking to quickly review or practice essential RDD and DataFrame operations.

🚀 What's Inside?
1. RDD Deep Dive 🔢
Practice working with Spark's foundational data structure:

Stats: Calculate sum, mean, min, max, and count for large numerical datasets.

Filtering & Grouping: Separate even/odd numbers and group custom tuple data (Name, Age).

Text Processing: Load text data, count lines, and perform word frequency analysis (tokenization, stop-word removal).

2. DataFrame Mastery 📊
Hands-on with Spark's high-level, optimized API:

Querying: Use SQL-like commands to select columns and filter rows based on criteria (e.g., employees older than 28).

Aggregation: Compute overall averages and run grouped aggregations (e.g., average salary per employee name).

Data Cleaning: Implement methods to handle missing values (nulls) by filling them with a default string or calculated column means.
