ğŸ PySpark Fundamentals Practice
A concise Jupyter notebook (Pyspark_Practice.ipynb) for mastering core Apache Spark data processing using the PySpark API.

This repository is an excellent resource for anyone looking to quickly review or practice essential RDD and DataFrame operations.

ğŸš€ What's Inside?
1. RDD Deep Dive ğŸ”¢
Practice working with Spark's foundational data structure:

Stats: Calculate sum, mean, min, max, and count for large numerical datasets.

Filtering & Grouping: Separate even/odd numbers and group custom tuple data (Name, Age).

Text Processing: Load text data, count lines, and perform word frequency analysis (tokenization, stop-word removal).

2. DataFrame Mastery ğŸ“Š
Hands-on with Spark's high-level, optimized API:

Querying: Use SQL-like commands to select columns and filter rows based on criteria (e.g., employees older than 28).

Aggregation: Compute overall averages and run grouped aggregations (e.g., average salary per employee name).

Data Cleaning: Implement methods to handle missing values (nulls) by filling them with a default string or calculated column means.
